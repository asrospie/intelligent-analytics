{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Two_Class_Gaussian_Data.txt') as f:\n",
    "    gaussian_lines = f.readlines()\n",
    "    for idx, line in enumerate(gaussian_lines):\n",
    "        gaussian_lines[idx] = line.strip()\n",
    "\n",
    "with open('Two_Class_Uniform_Data.txt') as f:\n",
    "    uniform_lines = f.readlines()\n",
    "    for idx, line in enumerate(uniform_lines):\n",
    "        uniform_lines[idx] = line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(uniform_lines):\n",
    "    if 'Class' in line:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A LEN : 250 :: B LEN : 250\n"
     ]
    }
   ],
   "source": [
    "g_a_x = gaussian_lines[10:260]\n",
    "g_b_x = gaussian_lines[263:514]\n",
    "u_a_x = uniform_lines[10:260]\n",
    "u_b_x = uniform_lines[263:514]\n",
    "\n",
    "for i in range(len(g_a_x)):\n",
    "    tmp_g_a = g_a_x[i].split()\n",
    "    g_a_x[i] = [float(tmp_g_a[0]), float(tmp_g_a[1])]\n",
    "\n",
    "    tmp_g_b = g_b_x[i].split()\n",
    "    g_b_x[i] = [float(tmp_g_b[0]), float(tmp_g_b[1])]\n",
    "\n",
    "    tmp_u_a = u_a_x[i].split()\n",
    "    u_a_x[i] = [float(tmp_u_a[0]), float(tmp_u_a[1])]\n",
    "\n",
    "    tmp_u_b = u_b_x[i].split()\n",
    "    u_b_x[i] = [float(tmp_u_b[0]), float(tmp_u_b[1])]\n",
    "\n",
    "print(f'A LEN : {len(u_a_x)} :: B LEN : {len(u_b_x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [ -1 for x in range(0, len(u_a_x)) ] + [ 1 for x in range(0, len(u_b_x)) ]\n",
    "x = u_a_x + u_b_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    w = np.array([])\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def train(self, x_train, y_train, learning_rate=.01) -> None:\n",
    "        # Checking for potential errors\n",
    "        if len(x_train) != len(y_train):\n",
    "            print(f'ERROR :: x_train ({len(x_train)}) and y_train ({len(y_train)}) lengths do not match')\n",
    "\n",
    "        # Initialize the weights\n",
    "        self.w = np.zeros(len(x_train[0]) + 1)\n",
    "\n",
    "        # Number of training vectors\n",
    "        m = len(x_train)\n",
    "\n",
    "        # Convergence loop\n",
    "        converged = False\n",
    "        time_step = 0\n",
    "        while not converged:\n",
    "            num_converged = 0\n",
    "            predictions = []\n",
    "            for i, x in enumerate(x_train):\n",
    "                prediction = self.predict(x)\n",
    "                predictions.append(prediction)\n",
    "\n",
    "                # Update bias\n",
    "                self.w[0] = self.w[0] + learning_rate * (y_train[i] - prediction)\n",
    "\n",
    "                # Update other weights\n",
    "                for j, val in enumerate(x):\n",
    "                    self.w[j + 1] = self.w[j + 1] + learning_rate * (y_train[i] - prediction) * val\n",
    "\n",
    "\n",
    "            # Check for convergence\n",
    "            num_converged = 0\n",
    "            \n",
    "            for idx, pre in enumerate(predictions):\n",
    "                if pre == y_train[idx]:\n",
    "                    num_converged += 1\n",
    "                    \n",
    "            if num_converged == m:\n",
    "                converged = True\n",
    "                \n",
    "            # Give user feedback based on time set and success rate of current weights and bias\n",
    "            success_rate = num_converged / m\n",
    "            print(f'TIME STEP {time_step} :: SUCCESS RATE {success_rate:.3f} :: WEIGHTS {self.w}')\n",
    "            \n",
    "            time_step += 1\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        # retrieve bias and add it to the prediction\n",
    "        prediction = self.w[0]\n",
    "\n",
    "        # Sum the weights and inputs to get prediction\n",
    "        for i, val in enumerate(x):\n",
    "            prediction += self.w[i + 1] * val\n",
    "\n",
    "        # If prediction is less than 0 -> Class A, greater -> Class B\n",
    "        return -1 if prediction <= 0 else 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, split_val=.75):\n",
    "    assert len(x) == len(y)\n",
    "    n = len(x)\n",
    "\n",
    "    p = np.random.permutation(n)\n",
    "\n",
    "    x_p = np.array(x)[p]\n",
    "    y_p = np.array(y)[p]\n",
    "\n",
    "    divider = int(n * split_val)\n",
    "\n",
    "    return (x_p[0:divider], x_p[divider:-1], y_p[0:divider], y_p[divider:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME STEP 0 :: SUCCESS RATE 0.909 :: WEIGHTS [-0.16      0.042702  0.04666 ]\n",
      "TIME STEP 1 :: SUCCESS RATE 0.981 :: WEIGHTS [-0.18      0.042964  0.077114]\n",
      "TIME STEP 2 :: SUCCESS RATE 1.000 :: WEIGHTS [-0.18      0.042964  0.077114]\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron()\n",
    "\n",
    "p.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: -1 :: Actual: -1\n",
      "Prediction: 1 :: Actual: 1\n",
      "Prediction: -1 :: Actual: -1\n",
      "1.0000 (124 / 124)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(x_test)):\n",
    "    prediction = p.predict(x_test[i])\n",
    "    if prediction == y_test[i]:\n",
    "        correct += 1\n",
    "    print(f'Prediction: {prediction} :: Actual: {y_test[i]}')\n",
    "\n",
    "print(f'{(correct / len(x_test)):.4f} ({correct} / {len(x_test)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2.7810836,2.550537003],\n",
    "\t[1.465489372,2.362125076],\n",
    "\t[3.396561688,4.400293529],\n",
    "\t[1.38807019,1.850220317],\n",
    "\t[3.06407232,3.005305973],\n",
    "\t[7.627531214,2.759262235],\n",
    "\t[5.332441248,2.088626775],\n",
    "\t[6.922596716,1.77106367],\n",
    "\t[8.675418651,-0.242068655],\n",
    "\t[7.673756466,3.508563011]]\n",
    "b = [-1, -1, -1, -1, -1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME STEP 0 :: SUCCESS RATE 0.900 :: WEIGHTS [0.02       0.15255062 0.05518524]\n",
      "TIME STEP 1 :: SUCCESS RATE 0.600 :: WEIGHTS [-0.02        0.15223856 -0.07588862]\n",
      "TIME STEP 2 :: SUCCESS RATE 0.900 :: WEIGHTS [-0.04        0.09661688 -0.12689936]\n",
      "TIME STEP 3 :: SUCCESS RATE 1.000 :: WEIGHTS [-0.04        0.09661688 -0.12689936]\n"
     ]
    }
   ],
   "source": [
    "p.train(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}